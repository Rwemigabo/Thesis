%************************************************
\chapter{Specification and Design}\label{ch:mathtest} % $\mathbb{ZNR}$
%************************************************
In this chapter, I present the requirements specification and design of the project in two sections. In the first section, some of the most important functional requirements of the full system are presented and then, the functional requirements of the individual components of the system are presented. After this, some of the use cases of the system as a whole are presented in the following section and including some design patterns after which the logical view of the system is presented in two images, which depict the interactions of the components and the functions performed by these components.

\section{Requirements Specification}
Some of the requirements presented in \cite{gomez2014cloud} provided a template upon which to start writing my system's main functional requirements, as they cover the functional and non-functional aspects to enable the dynamic (re-)distribution of applications in the cloud, which is the aim of my system. However, during the development of the system, a few other functional requirements were realised and added to the list for both the system and its individual components.

\subsection{{System's Functional requirements}}
\begin{itemize}
    \item [FR1] The System should be able to connect to or interact with a containerisation engine.
    \item [FR2] The System should have access to the containerisation engine's API.
    \item [FR3] The System should order the services of the application being manage into a list.
    \item [FR4] The System should have access to the alternative viable topologies.
    \item [FR5] The System should be able to Monitor data from the managed Application.
     \item [FR6] The System should be able to Analyse the data from the managed Application
     \item [FR7] The System should be able to make a Plan using the data from the analysis of the managed Application.
     \item [FR8] The System should be able to Execute the plan made for the managed Application
    \item [FR9] The System should create Monitors for each of the services in the managed Application.
    \item [FR10] The System should create Analysers for each of the services of the managed Application.
     \item [FR11] The System should have access to the Service Level Agreements or Service Level Objectives set by the user.
\end{itemize}

\subsection{Component Requirements}

\subsubsection{\textbf{Monitor Component}}
\begin{itemize}
    \item [FR11] The Monitor component should create sensors for each of the containers of the service it is monitoring.
    \item [FR12] The Monitor component should log statistics for each of the containers of the service being monitored.
    \item [FR13] The Monitor component should set the sensors to monitor different application metrics.
    \item [FR14] The Sensor(s) should check that the metric values recorded are within the SLOs.
    \item [FR15] The Monitor component should notify the analysis whenever a new statistic is recorded. 
    \item [FR16] The Monitor component should notify (differently/ Urgently) the analysis whenever a metric out of scope of the set SLA/ SLO is recorded by the sensor(s).
    \item [FR17] The Monitor component should save the monitored statistics to the knowledge base.
    \item [FR18] The Monitor component should continuously monitor the service until the point that it is no longer available.
\end{itemize}

\subsubsection{\textbf{Analysis Component}}
\begin{itemize}
    \item [FR21] The Analysis Component should receive notifications from the Monitor component of new statistics.
    \item [FR22] The Analysis Component should perform data analysis in time windows defined by the user.
    \item [FR23] The Analysis Component should retrieve a batch of statistics in a given time window for analysis from the knowledge base.
    \item [FR24] The Analysis Component should perform a set of analysis tactics on the statistics gathered from the knowledge base.
    \item [FR25] The Analysis Component should provide a visual representation of the analysed data.
    \item [FR26] The Analysis Component should perform a prediction of data points for the next time window.
    \item [FR27] The Analysis Component should make an estimation of the resources that need to be added, removed or kept as is.
    \item [FR28] The Analysis Component should make an aggregation of the results from the various analysers.
    \item [FR29] The Analysis Component should create a topology suggestion using this estimation based on the topology running and the aggregated results.
    \item [FR210] The Analysis Component should notify the plan component of the new topology suggestion.
    \item [FR211] The Analysis Component should save the results from the analysis to the knowledge base.
    \item [FR212] The Analysis Component should save the topology suggestion to the knowledge base.
\end{itemize}

\subsubsection{\textbf{Plan Component}}
\begin{itemize}
    \item [FR31] The Plan Component should be able to receive notifications from the Analysis Component.
    \item [FR32] The Plan Component should have access to the list of alternative viable application topologies in the Knowledge base.
    \item [FR33] The Plan Component should have access to the suggested topology from the Analysis Component in the Knowledge base.
    \item [FR34] The Plan Component should ensure enough time (set by user) has passed since last topology (re-)distribution.
    \item [FR35] The Plan Component should retrieve the latest suggested topology baby the Analysis component.
    \item [FR36] The Plan Component should make a comparison between the suggested topology from the Analysis Component to the alternative viable application topologies in the Knowledge base.
    \item [FR37] The Plan Component should retrieve the alternative viable topology closest in similarity to the suggested topology.
    \item [FR37] The Plan Component should have record of the currently running or deployed topology.
    \item [FR38] The Plan Component should notify the Execution component if a change is required.
    \item [FR39] The Plan Component should store the new topology for the (re-)distribution in the Knowledge Base
\end{itemize}

\subsubsection{\textbf{Execution Component}}
\begin{itemize}
    \item [FR41] The Execution component should be able to receive notifications from the Plan component.
    \item [FR42] The Execution component should create an Effector, whose job it is to perform the execution actions.
    \item [FR43] The Execution component should have access to the alternative topologies available in the Knowledge base.
    \item [FR44] The Execution component should have access to the containerisation API.
    \item [FR45] The Execution component should be able to run the commands necessary to make the topology change requested by the plan component.
    \item [FR46] The Execution component should confirm when the change has been made successfully
    \item [FR47]The Execution component should record the time of the latest change of topology.
    \item [FR48] The Execution component should record the time it took to make the change and update it in the knowledge base
    \item [FR49] The Execution component should be able to reset the MAPE-K loop to start working on the newly redistributed topology.
    \item [FR410] The Execution component should update the currently running topology.
    \item [FR411] The Execution component should save the new topology change to the knowledge base.
\end{itemize}

\subsubsection{\textbf{Knowledge Base Component}}
\begin{itemize}
    \item [FR51] The Knowledge Base Component should provide an access point for the various components to create the necessary data.
    \item [FR52] The Knowledge Base Component should provide an access point for the various components to update the necessary data.
    \item [FR53] The Knowledge Base Component should provide an access point for the various components to retrieve the necessary data.
    \item [FR54] The Knowledge Base Component should provide an access point for the various components to delete data.
    \item [FR55] The Knowledge Base Component should contain a record of the alternative viable topologies.
    \item [FR56] The Knowledge Base Component should contain a record of the statistics recorded by the monitor component.
    \item [FR57] The Knowledge Base Component should contain a record of the data output by the analysis component.
    \item [FR58] The Knowledge Base Component should contain a record of the topology picked by the plan component to be deployed.
    \item [FR59] The Knowledge Base Component should contain a record of the successful topology changes made by the execution component including the time.
    \item [FR510] The Knowledge Base Component should contain a record of the service level objectives set by the system user.
    \item [FR511] The Knowledge Base Component should contain a record of the other user preferences like the time windows for the analysis e.t.c.
    \item [FR512] The Knowledge Base Component should contain a record of the history of the performance of the various topologies that have been run before.
\end{itemize}
\newpage
\section{Design} % \ensuremath{\NoCaseChange{\mathbb{ZNR}}}
In this Section, I presents 2 use cases, which are cases under which the system is expected to behave differently. In the first case, the system records normal workloads under which the managed application should not have any problems dealing with and therefore, there is no need for a change. In the second use case, the system predicts stress on some of the services of the managed application or under use of the resources and therefore requires an appropriate change to be made in order for the application to utilise it's available resources optimally.
\subsection{Use Cases}
\begin{usecase}
	\addtitle{Use Case 1}{Normal Managed Application load}
	\addfield{Goal:}{This use case depicts a situation where the managed application load is predicted to be within the Service Level Objectives defined by the application owner. With this case, the system is expected to keep reporting the normal application usage and not make any changes to the topology}
	\addfield{Pre-Condition:}{The managed application is running, the system is deployed on top of it and is monitoring the usage statistics of the application }
	\addfield{Post-Condition:}{The System has run an analysis of the statistics and detected that no changes are required and hence, there are no changes made and the monitoring and analysis process continues.}
	\addfield{Primary Actor:}{Managed application}
	\additemizedfield{Assumptions:}{\item Alternative Viable topologies are made available by the application owner.
	\item The Service Level Objectives are defined by the application owner.
	\item The application services are running normally
	\item The application traffic is predicted to be on par with the resources made available to the application.
	\item The User has set other parameters like the preferred time windows for analysis.}
	\addscenario{Main Success Scenario:}{\item The system deploys its MAPE-K control loop on the application services.
	\item The system gains access to the containerisation API.
	\item The monitor functionality records the statistics received from the containerisation API and reports to the Analysis.
	\item The analysis component makes a record of the time of the first notification/ statistic from the monitor component.
	\item The analysis component compares the current system time with the recorded time every time it is notified.
	\item After the correct (set by the user) time window has passed, the analysis component makes a record of that last timestamp and performs an analysis action on the data of the time window.
	\item The analysis component makes a prediction of the expected workload in the next time window and suggests the number of containers required to be added or removed
	\item The number to be added or removed is 0 and therefore no further actions are required.
	\item The analysis component continues to compare the current time to the last recorded timestamp for the next analysis window}
	\addscenario{Extensions (Temporary Spike):}{\item [3a] The Monitor functionality reports high metrics and shortens the time window to the analysis.
	\item [6a] Analysis is performed on the shorter time window and predicts that increased use was a temporary spike so, no additional resources should be provisioned.}
 \end{usecase}
 
 \begin{usecase}
	\addtitle{Use Case 2}{High/ Low Managed Application load}
	\addfield{Goal:}{This use case depicts a situation where the managed application load is predicted to be outside the Service Level Objectives defined by the application owner. With this case, the system is expected to make a change in the topology being used by the managed application and therefore get the application back within the Service Level Objectives set by the user.}
	\addfield{Pre-Condition:}{The managed application is running, the system is deployed on top of it and is monitoring the usage statistics of the application.}
	\addfield{Post-Condition:}{The System has run an analysis of the statistics and predicted values outside the SLOs and therefore a change in topology is performed and a new topology is being used by the managed application.}
	\addfield{Primary Actor:}{Managed application}
	\additemizedfield{Assumptions:}{\item Alternative Viable topologies are made available by the application owner.
	\item The Service Level Objectives are defined by the application owner.
	\item The application services are running normally
	\item The application traffic is predicted to be outside the set SLOs within the next time window.
	\item The User has set other parameters like the preferred time windows for analysis.}
	\addscenario{Main Success Scenario:}{\item The system deploys its MAPE-K control loop on the application services.
	\item The system gains access to the containerisation API.
	\item The monitor functionality records the statistics received from the containerisation API and reports to the Analysis.
	\item The analysis component makes a record of the time of the first notification/ statistic from the monitor component.
	\item The analysis component compares the current system time with the recorded time every time it is notified.
	\item After the correct (set by the user) time window has passed, the analysis component makes a record of that last timestamp and performs an analysis action on the data of the time window.
	\item The analysis component makes a prediction of the expected workload in the next time window and suggests the number of containers required to be added or removed
	\item The number to be added or removed is greater or less than 0 and therefore a change in topology is required.
	\item The Analysis component makes an addition and/ or subtraction to the resources available in the current topology therefore coming up with a recommendation of a topology like structure for the required resources
	\item The recommendation is saved and the Plan component is notified.
	\item The Plan component checks the time of the last Topology change.
	\item If enough time has passed since the last Topology change, the Plan component accesses the alternative topologies in the knowledge base and selects the one closest to the suggested topology
	\item The Plan component notifies the execution component of the required change and saves the suggestion.
	\item The Execution component retrieves the selected topology and runs the required commands to redeploy the application in the new topology.
	\item The Execution component updates the time to redeploy the application.
	\item The execution component updates the last successful redeployment time and resets the system to run on the new topology.
	\item The loop restarts}
	\addscenario{Extensions (Reactive):}{\item [3a] The Monitor functionality reports high metrics and shortens the time window to the analysis.
	\item [6a] Analysis is performed on the shorter more urgent time window.
	\item [7a] A prediction is made and the prediction is outside the SLO.
	\item [10a] Plan is notified with an urgency/ priority recommendation.
	\item [11a] No time check is performed.}
	\addscenario{Extensions (Oscillation Mitigation):}{ \item [11a] Not enough time passed triggers wait action (Depending on how close to breaking point system is predicted to be).}
 \end{usecase}
 
\newpage
\section{System Architecture}
\subsection{Activity Diagram}
In the diagram below, the activities required to perform the functionalities in the particular component instances are presented. The monitor and analysis components have multiple instances and are managed by the monitor manager or the Analyser manager and therefore these managers ensure the aggregation of data for the entire application topology being managed. The details of the manager and individual components shall be discussed in the following chapter. At the start of the system, each of these components are created by their managers and their activities after that are as follows.
\subsubsection{Monitor}
 A monitor component is created for each container in the particular service being monitored. This component starts off by creating sensors for each of the metrics it is meant to monitor for that container and then the monitoring task begins. Every 2 seconds, the Sensors send their registered metric to the monitor component and these are metrics are collected to form a statistic. A sensor can also report a metric which is outside the SLOs and this will cause the component to create a new more urgent statistic. After the statistic is created it is stored to the Knowledge base and the Analyser is notified.
\subsubsection{Analyse}
An analyser is also created for each of the containers of a service therefore, the analysers and monitor components have a one to one relationship. When an analyser is created, it waits for it's first notification from the sensor it has a relation with and when it receives it, the analyser takes note of the time in the first statistic the sensor saved. After this point, the time window is checked every time a notification is received and when enough time has passed, the components retrieves the statistics for that window, sets the last timestamp as the latest time and analyses the data. On the other hand, an analysis is also performed on double time windows to get a more clear analysis with more data. After the analysis is done, the manager aggregates the data and notifies the plan if necessary of a necessary change.
\begin{figure} 
   \centering 
   \begin{turn}{90}
   \includegraphics[scale=0.50]{gfx/Activity_Diagram1.png}
   \end{turn}
   \caption{ Activity Diagram} 
   \label{Fig:1} 
\end{figure}


%*****************************************
%*****************************************
%*****************************************
%*****************************************
%*****************************************
