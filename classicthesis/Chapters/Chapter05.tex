%************************************************
\chapter{Testing}\label{ch:testing} % $\mathbb{ZNR}$
%************************************************

During the development of the system, there were a battery of tests run on each of the individual components to ensure their functionality and furthermore their interaction with each other when integrated in order to ensure that they work together. However, this chapter presents the more important tests run on the more complete versions of the system. After implementing three of the major components of the system, that is the Sensor, Monitor and the Analysis components, the more important phase of testing begun and in the following sections, I present the results of most of these tests and finally, an evaluation of the results of the System is done in the following chapter.
\section{Test Suite}
\subsection{Test Application}
The testing of the system was done using two different applications assembled from Github. These applications include:\\\\
\textbf{example-voting-app:}\\
After the initial testing of my system's Monitor and and Analysis components and confirming that they performed the basic functionality, I needed to test the more complex features of the Analysis component, which were the prediction and recommendation functionalities. To test these, I needed a simpler more basic application where I would be able to quickly write a testing script for the load simulator application I was going to use so, I decided to use \cite{example-voting-app} Example Voting App. It is a simple voting application where a user either vote cat or dog. I also decided to use this application because I was having problems with the login feature that was on the application introduced in the section above so, to save time, I changed applications and found this second micro service docker application among the other available options on Github.\\
The services in this Application include the \textit{voting-app} service, where the users case their votes, \textit{result-app} service, which is where the user views the vote tally percentage, which is retrieved from the database, \textit{redis} service, a queue to handle the votes coming it, \textit{worker} service to process the voted and send them to the final database service \textit{db} service.
\begin{figure} [H]
   \centering 
   \includegraphics[scale=0.40]{gfx/voteApp.png}
   \caption{ Architecture of the test application} 
   \label{Fig:3} 
\end{figure}
\subsection{Load simulator}
Locust IO\cite{locustIO}, the Load testing application introduced in \autoref{ch:implementation} was used for to load test the test applications. I wrote the test scripts for the test applications for example the short test script from the load testing done on the Example Voting App is presented in \autoref{lst:script1}. By running this script, the simulated user simply initially randomly performs a vote and then randomly changes the vote every time locust sends a request by the simulated user. \autoref{lst:script2} provides the ports where the simulated users can connect.

\begin{lstlisting}[language=Python, caption=Example Voting App testing Script, label= lst:script1]
from locust import TaskSet, task
import random
class MyTasks(TaskSet):
    # vote = null
    # vote function
    def vote(self, vt):
        self.client.post("/", {'vote': vt})

    # initial random vote between cats or dogs
    @task(2)
    def votecat(self):
        self.vote("a")

    # change vote task
    @task(3)
    def votedg(self):
        self.vote("b")
\end{lstlisting}

\begin{lstlisting}[language=Python, caption=Locust open ports Script, label= lst:script2]
from locust import HttpLocust
from MyTaskSet import MyTasks
# from MyTaskSet import MyServicesTasks


class MyLocust(HttpLocust):
    task_set = MyTasks
    min_wait = 10
    max_wait = 100
    host = 'http://localhost:5000'


# class MyServicesLocust(HttpLocust):
#     task_set = MyServicesTasks
#     min_wait = 10
#     max_wait = 100
#     host = 'http://localhost:5001'


\end{lstlisting}

\section{Sensor, Monitor and Analysis Component Testing.}
As seen in the Component diagrams in \autoref{ch:implementation}, the These components work closely together and in order to fully test one of them, I had to have all of them working. For the testing phase of these components, I started out by testing the Sensor connection to the Docker API to see whether the statistics metrics were being accurately monitored by the sensor and to confirm, I compared them to the container statistics produced when running the command \textit{docker stats} in the terminal. After confirmation of the accuracy of the sensor statistics, I moved on to the monitoring component. Since there is a monitor instance for each of the services being monitored, I decided to plot graphs for each of the statistics for each of the metrics. Therefore creating 2 plots per container per service. \autoref{Fig:7} shows a sample of the statistics recorded from testing the Example voting application. 
\begin{figure}[H]
\centering
  \subfloat[Result service container CPU stats]{%
    \includegraphics[width=0.49\textwidth]{gfx/result_FullCPUDatapoints_0}}\hfill
  \subfloat[Vote service container CPU stats]{%
    \includegraphics[width=0.49\textwidth]{gfx/vote_FullCPUDatapoints_0}}\hfill   
    \subfloat[Worker service container CPU stats]{%
    \includegraphics[width=0.49\textwidth]{gfx/worker_FullCPUDatapoints_0}}\hfill
  \subfloat[db service container CPU stats]{%
    \includegraphics[width=0.49\textwidth]{gfx/postgres_FullCPUDatapoints_0}}\hfill
    \subfloat[Redis service container CPU stats]{%
    \includegraphics[width=0.49\textwidth]{gfx/redisalpine_FullCPUDatapoints_0}}
    \caption{Plots of the monitored CPU statistics from the containers of the example voting application.} 
   \label{Fig:7} 
\end{figure}

These Images show the a small sample of the testing done on the application and after the confirmation of the basic communications between the Monitor and sensor components, I then moved to the Analysis Component. From this component, my aim was to see it perform a prediction of the usage for the next time window (5 minutes) given the analysis of the already recorded data. To visualise the results of this functionality, I used the same plotting mechanism implemented for the statistics and the prediction data can be seen in \autoref{Fig:8}, where the prediction of the CPU data for the next time window is performed based on the data from the results in \autoref{Fig:7}.
\begin{figure}[H]
\centering
  \subfloat[Result service container CPU prediction stats]{%
    \includegraphics[width=0.5\textwidth]{gfx/result_PredictionforCPU_0}}\hfill
  \subfloat[Vote service container CPU prediction stats]{%
    \includegraphics[width=0.5\textwidth]{gfx/vote_PredictionforCPU_0}}\hfill   
    \subfloat[Worker service container CPU prediction stats]{%
    \includegraphics[width=0.5\textwidth]{gfx/worker_PredictionforCPU_0}}\hfill
  \subfloat[db service container CPU prediction stats]{%
    \includegraphics[width=0.5\textwidth]{gfx/postgres_PredictionforCPU_0}}\hfill
    \subfloat[Redis service container CPU prediction stats]{%
    \includegraphics[width=0.5\textwidth]{gfx/redisalpine_PredictionforCPU_0}}
    \caption{Plots of the predicted CPU statistics from the containers of the example voting application.} 
   \label{Fig:8} 
\end{figure}

\section{Full System Testing }
After the confirmation of the Monitor and analysis components, the next step of testing brought us to the version of the system after the implementation of the fuzzy logic functionality in the Analysis component, which is meant to use the predicted data and decide how many containers need to be added to or removed from the service, and the Plan component, which works with that data/ recommendation from the Analysis component and proposes the topology that best suits the recommendation before notifying the execution component to change the topology.\\
In order to confirm the above, I had to run varying loads through the application so that the system would respond accordingly. So, the Locust load simulation tool was used for this purpose and the work loads to be tested with are presented in \autoref{systest} below. \autoref{tops} shows the simulated topology structures of the test application Example Voting app introduced in the Test suite section .The table shows the services in the top row and every other row shows the number of containers for that service in that topology. These topologies were used for the purpose of providing the planning component a simplified example of different topology structures that it can switch between. The last 2 columns are based on pricing of Amazon's General purpose dedicated host virtual machines \cite{amazonprices}. These are represented in the table as small, medium and large representing the m4 = 2.42 USD per hour, m5 = 5.069 USD per hour and m5d = 5.966 USD per hour options respectively per hour from Amazon EC2 services.

\begin{table}[H]
\resizebox{\textwidth}{!}{%
\centering
\begin{tabular}{|l|l|l|l|l|l|l|l|}
\hline
Topology & Worker & Vote & db & Redis & result & Virtual Machines & total Price (USD) \\ \hline
T1 & 1 & 1 & 1 & 1 & 1 & 1 Small & 2.42 \\ \hline
T2 & 2 & 1 & 1 & 1 & 1 & 2 Small & 4.84 \\ \hline
T3 & 3 & 2 & 1 &1 & 1 & 1 Medium  & 5.069 \\ \hline
T4 & 4 & 3 & 2 & 1 &1 & 1 Medium & 5.069\\ \hline
T5 & 4 & 4 & 3 & 2 & 1 & 2 Medium & 10.138\\ \hline
T6 & 4 & 4 & 4 & 3 & 2 & 2 Medium &10.138\\ \hline
T7 & 4 & 4 & 4 & 4 & 3 & 1 Large &5.966\\ \hline
T8 & 4 & 4 & 4 & 4 & 4 & 2 Large &11.932\\ \hline
\end{tabular}%
}
\caption{Topology options for the testing of the application}
\label{tops}
\end{table}

\subsection{Test Case 1(Upscale request)}
For the first test case, I ran the system to test for its ability to request for a topology with an increased number resources (containers) available to the application for the next time window as seen in \autoref{systest}. The starting Topology for this test case was Topology 1 (T1) as seen in \autoref{tops}above. The results of this testing are as seen below.
\begin{table}[H]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|l|l|l|}
\hline
 Test &Users | Requests (/s) & average response time & Result & Topology \\ \hline
1& 3 | 45 & 14(ms) & No Adaptation  & T1 \\ \hline
2 & 8 | 102 & 23(ms) &  Adaptation & T3\\ \hline
3 & 15 | 122 &  53(ms) & Adaptation& T4 \\ \hline
4 & 30 | 160 &  141(ms) & Adaptation & T4 \\ \hline
\end{tabular}%
}
\caption{Test case 1 run on the application.}
\label{systest}
\end{table}

In the tests where a change in the topology was requested (scale up) for example Test 4, the recommendation of the new topology structure was triggered by one of the services (Vote) requiring a lot more computing power and therefore the system suggesting more containers for the component. An example of the structure of the recommended topology can be seen in \autoref{RecTopconsoleoutput} for tests 3 and 2.
\begin{figure} [H]
   \centering 
   \subfloat[Test 2]{%
   	\includegraphics[width=0.60\textwidth]{gfx/RecTopology2}}\hfill
   \subfloat[Test 3]{%
   	\includegraphics[width=0.60\textwidth]{gfx/RecTopology}}
   \caption{ Recommended Topology output} 
   \label{RecTopconsoleoutput} 
\end{figure}


\subsection{Test Case 2(Different topology testing)}
This test was done to confirm both the system's functionality after a new Topology has been deployed and the up and down scaling requests of the system when given different loads. The tests run in this test case start with Topology 3 (T3) after the load (number of users) that caused the adaptation switch.
\begin{table}[H]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|l|l|l|}
\hline
 Test & Users | Requests(/s) & average response time & Result & Topology \\ \hline
1& 15 | 50 & 130(ms) & Adaptation  & T2 \\ \hline
2 & 80 | 130 &383 (ms) & Adaptation & T4 \\ \hline
3 & 200 | 190 &  572(ms) & Adaptation& T4 \\ \hline
\end{tabular}%
}
\caption{Test case 2 run on the application.}
\label{systest1}
\end{table}

The selections of the next topology to run from the above tests for the next time window are selected based on the recommended topology by the system as seen in \autoref{RecTopconsoleoutput2} below. 

\begin{figure} [H]
   \centering 
   \subfloat[Test 1]{%
   	\includegraphics[scale=0.30]{gfx/T3output}}\hfill
    \subfloat[Test 3]{%
   	\includegraphics[scale=0.30]{gfx/test3}}
   \caption{ Recommended Topology output} 
   \label{RecTopconsoleoutput2} 
\end{figure}

