%*****************************************
\chapter{Evaluation}\label{ch:evaluation}
The objective of this work was to design, develop, and test an IDE supporting the lifecycle seen in the paper \cite{andrikopoulos2017engineering}. To evaluate the system developed, I shall present a checklist of requirements that were realised in \autoref{ch:mathtest} and show the ones fulfilled by the system.  Finally for the evaluation, I shall present a case study application used to validate the system, this application is more significant in terms of the number of services that were available in the test application and therefore, it provides better value in relation to a real world we application.

\section{Evaluation}
In this section, I review the requirements realised by the developed system using the tables below containing the requirement and whether it was implemented into the system or not and a relevant test that corresponds this functionality.\\
\textbf{System Requirements}
\begin{table}[H]
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lllllllllllll@{}}
\toprule
 Requirements & FR1 & FR2 & FR3 & FR4 & FR5 & FR6 & FR7 & FR8 & FR9  & FR10 & FR11 &  \\ \midrule
 Realised & \cmark & \cmark & \cmark &  & \cmark & \cmark & \cmark &  & \cmark & \cmark & \cmark &  \\ \midrule
 Test &  &  &  &  &  &  &  &  &  &  &  & \\ \bottomrule
\end{tabular}%
}
\caption{System Functional Requirements evaluation}
\label{my-label1}
\end{table}

\textbf{Monitor Component Requirements}
\begin{table}[H]
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lllllllllllll@{}}
\toprule
Requirements & FR11 & FR12 & FR13 & FR14 & FR15 & FR16 & FR17 & FR18 &   &  &  &  \\ \midrule
 Realised & \cmark & \cmark & \cmark &  & \cmark &  &  & \cmark &  &  &  &  \\ \midrule
 Test &  &  &  &  &  &  &  &  &  &  &  & \\ \bottomrule
\end{tabular}%
}
\caption{Monitor Component Functional Requirements evaluation}
\label{my-label2}
\end{table}

\textbf{Analysis Component Requirements}
\begin{table}[H]
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lllllllllllll@{}}
\toprule
Requirements & FR21 & FR22 & FR23 & FR24 & FR25 & FR26 & FR27 & FR28 & FR29  & FR210 & FR211 & FR212 \\ \midrule
 Realised & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark &  &  \\ \midrule
 Test &  &  &  &  &  &  &  &  &  &  &  & \\ \bottomrule
\end{tabular}%
}
\caption{Analysis Component Functional Requirements evaluation}
\label{my-label3}
\end{table}

\textbf{Plan Component Requirements}
\begin{table}[H]
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lllllllllllll@{}}
\toprule
 Requirements & FR31 & FR32 & FR33 & FR34 & FR35 & FR36 & FR37 & FR38 & FR39 & FR310 &  &  \\ \midrule
 Realised & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark &  &  &  \\ \midrule
 Test &  &  &  &  &  &  &  &  &  &  &  & \\ \bottomrule 
\end{tabular}%
}
\caption{Plan Component Functional Requirements evaluation}
\label{my-label4}
\end{table}

\textbf{Execution Component Requirements}
\begin{table}[H]
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lllllllllllll@{}}
\toprule
 Requirements & FR41 & FR42 & FR43 & FR44 & FR45 & FR46 & FR47 & FR48 & FR49  & FR410 & FR411 &  \\ \midrule
 Realised & \cmark &  & \cmark & \cmark & \cmark & \cmark & \cmark &  &  & \cmark &  &  \\ \midrule
 Test &  &  &  &  &  &  &  &  &  &  &  & \\ \bottomrule 
\end{tabular}%
}
\caption{Execution Component Functional Requirements evaluation}
\label{my-label5}
\end{table}

\section{Case Study (Sock Shop : A Microservice Demo Application)}
For this case study, the application is run and optimised with a setup of 1 container pre service. The application is made up of 14 services working together to complete the task. I use the locust load tester like in the testing phase in the previous chapter and the topologies are randomly generated by a the code in \autoref{lst:code}, which uses the available service names from the currently running topology, creates 6 new topologies, adds a random number of containers (1-5) to each of the services, assigns a random number of Virtual machines to the topologies with random sizes and adds the topologies to the list of viable ones.

\begin{lstlisting}[language=Java, caption=Viable Topology definition code, label= lst:code]
		public void defineDynamicTopologies2() {

		ArrayList<String> myservs = createServices();
		Topology t1 = DockerManager.getInstance().getCurrentTopology();
		t1.setFilename("Current Topology");
		if (t1.getVMS().size() < 1) {
			t1.addVM(new SmallVM());
			t1.addVM(new SmallVM());
			t1.setFilename("Current Topology");
		}
		addTopology(t1);
		Topology vtop2 = new Topology("top1");
		Topology vtop3 = new Topology("top2");
		Topology vtop4 = new Topology("top3");
		Topology vtop5 = new Topology("top4");
		Topology vtop6 = new Topology("top5");
		Topology vtop7 = new Topology("top6");
		

		addVMs(vtop2);
		addVMs(vtop3);
		addVMs(vtop4);
		addVMs(vtop5);
		addVMs(vtop6);
		addVMs(vtop7);
		addServices(myservs, vtop2);
		addServices(myservs, vtop3);
		addServices(myservs, vtop4);
		addServices(myservs, vtop5);
		addServices(myservs, vtop6);
		addServices(myservs, vtop7);
		addTopology(vtop2);
		addTopology(vtop3);
		addTopology(vtop4);
		addTopology(vtop5);
		addTopology(vtop6);
		addTopology(vtop7);

	}
	
			void addServices(ArrayList<String> s, Topology t) {
		int toprand = randomNumber(1, 3);
		for (String str : s) {
			if (toprand == 1) {
				t.addService(str, randomNumber(1, 3));
			} else if (toprand == 2) {
				t.addService(str, randomNumber(2, 4));
			} else {
				t.addService(str, randomNumber(3, 5));
			}

		}
	}	
\end{lstlisting}

The results of the tests run on the system monitoring and managing the application's resources are shown in \autoref{caseStudyTable} below. The system results of the first test run on the application are shown in the images that follow the table and the results of the rest of the tests can be found in the appendix.
\begin{table}[H]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|l|l|l|}
\hline
 Test & Users | Requests(/s) & average response time & Result & Topology \\ \hline
1& 15 | 141 & 42(ms) & Adaptation & Topology 2 \\ \hline
2 & 40 | 210 & 140 (ms) & Adaptation & Topology5, 2Medium VMs \\ \hline
3 & 300 | 220 &  1196(ms) & Adaptation & N/A \\ \hline
\end{tabular}%
}
\caption{Test case 2 run on the application.}
\label{caseStudyTable}
\end{table}

After running a number of tests on this application, I present the results of one of the tests below, which was run with the lower load seen above but because some of the resources required more than one container to function optimally, an adaptation was requested. These results can be seen in the images below and thereafter the defence for the necessity of the system.

\begin{figure} [H]
   \centering 
   \includegraphics[scale=0.50]{gfx/socksTopologyRecomm.png}
   \caption{ Recommended Topology outlay from the analysis done in test T1} 
   \label{CSFig} 
\end{figure}

\autoref{CSFig} shows the topology recommended by the system in terms of service to container count. These results are derived from the analysis of the monitored data and a prediction of the average load of the system for the next time window, which then is used to estimate the optimal number of containers for the system in the upcoming time window.

\begin{figure} [H]
   \centering 
   \includegraphics[scale=0.30]{gfx/bestOptions.png}
   \caption{The best options among the topology options available} 
   \label{CSFig1} 
\end{figure}

After the containers have been suggested, and a current system state is created, the Planner is notified and it makes a list of the topologies which best suit the recommended topology by assigning them scores as seen in \autoref{CSFig1} where the topology is stated and the score next to it.

\begin{figure} [H]
   \centering 
   \includegraphics[scale=0.40]{gfx/selected.png}
   \caption{ The topology selected by a combination of points and a low price} 
   \label{CSFig2} 
\end{figure}

\autoref{CSFig2} Some times there might be only one topology option available but this time there were 2 with the same score but however, the tie breaker in this case was the cost of the topology. There are other cases where the a number of topologies are available with lower scores but, as usual, the cost of the topology is usually the last barrier for a topology to cross before being selected by the system.\\
 
One of the other motives for performing the third test was to show the result of not performing the change in topology for a growing load for the application. At the simulated traffic of 300 users, the application request intake could not go beyond 217 requests per second and it started to drop from there as seen in the locust charts and data below. On top of that, there was no suitable topology defined for the simulated traffic as seen in \autoref{CSFig3} and therefore an adaptation was requested but not completed and therefore even the response times kept climbing presented in \autoref{CSFig5}. In conclusion to the Case Study, the application ended up costing a lot in terms of revenue lost as some of the important services started to produce a high failure rate in terms of the responses, which would cost a business highly for example as seen in the Locust statistics in \autoref{CSFig4}, the catalogue continuously failed to respond so the users wouldn't have been able to access the contents of the store.

\begin{figure} [H]
   \centering 
   \includegraphics[scale=0.40]{gfx/test3badoptions}
   \caption{All topologies labelled as bad options for the redeployment.} 
   \label{CSFig3} 
\end{figure}

\begin{figure} [H]
   \centering 
   \includegraphics[scale=0.25]{gfx/locustss}
   \caption{All topologies labelled as bad options for the redeployment.} 
   \label{CSFig4} 
\end{figure}

\begin{figure} [H]
   \centering 
   \includegraphics[scale=0.25]{gfx/locustchart}
   \caption{All topologies labelled as bad options for the redeployment.} 
   \label{CSFig5} 
\end{figure}

%*****************************************
%*****************************************
%*****************************************
%*****************************************
%*****************************************
